{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pacotes para executar operações gráfricas,tabulares,matemáticas\n\nimport numpy as np \nimport pandas as pd \nimport scipy.io as sio\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imshow\nfrom pylab import rcParams\n\n!pip install missingpy\n\n#pacotes para 'imputar' dados\nimport missingpy\nfrom missingpy import MissForest\nfrom sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Impute_data=pd.read_excel(\"/kaggle/input/impute/Impute.xlsx\")#ler conjunto de dados via pandas\n\nImpute_data #mostrar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#executar funções de 'imputar'\n\nRFORImp=MissForest()\nSKLSimple=SimpleImputer(missing_values=np.nan,strategy='median')\n\nSimple_Imp = Impute_data.fillna(method='ffill')\nSKL_Imp = pd.DataFrame(SKLSimple.fit_transform(Impute_data))\nRFOR_Tab = pd.DataFrame(RFORImp.fit_transform(Impute_data))#Random Forest Imputação e conversão por pandas\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#crear gráficos\n\nplt.plot(Simple_Imp.index,Simple_Imp ['Sedimentation'], label='Simple_Imp Sedimentation', linewidth=3, color='midnightblue')\nplt.plot(Simple_Imp.index,Simple_Imp ['Sedimentation_in_Dead_Storage'], label='Simple_Imp Sediment in Dead_Volume', linewidth=3, color='orange')\nplt.plot(SKL_Imp.index,SKL_Imp [0], label='Median_Imp Sedimentation', linewidth=3, color='darkgreen')\nplt.plot(SKL_Imp.index,SKL_Imp [1], label ='Median_Imp Sediment in Dead_Volume', linewidth=3, color='red')\nplt.plot(RFOR_Tab.index,RFOR_Tab [0], label='RFOR_Tab Sedimentation', linewidth=3, color='blueviolet')\nplt.plot(RFOR_Tab.index,RFOR_Tab [1], label ='RFOR_Tab Sediment in Dead_Volume', linewidth=3, color='saddlebrown')\n\nplt.legend(loc='right',fontsize=12)\n\n\nrcParams['figure.figsize'] = 16, 6\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# pacotes escencias por certas funciones como randomizar ou gerar certas representações gráficas \nimport os\nimport cv2\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\n# pacotes gerais de ANN\nimport tensorflow as tf \nfrom tensorflow import keras\n\n\n#from tensorflow.keras import datasets, layers, models\n\n# pacotes por certas operções ou câmaras de ANN\nfrom tensorflow.keras import optimizers, losses, utils \nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, Dropout\nfrom tensorflow.keras.models import Model, Sequential \nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.regularizers import l2\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATADIR = '/kaggle/input/eurosat/2750/' #lugar superior do conjunto de imagens\nCATEGORIES = [\"River\",\"Forest\",\"AnnualCrop\",\"HerbaceousVegetation\",\"Highway\",\"Industrial\",\"Pasture\",\"PermanentCrop\",\"Residential\",\"SeaLake\"]#conjuntos das categórias\n\ntraining_data = [] #lista vazia\nshow = []\n\n#rotação sobre Datadir e Categorias para a)marcar cada categoria com um número único b)unificar as imanges num arquivo só  \n        \n\ndef create_image_set():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)  \n        for img in os.listdir(path):\n            try: # try-except-pass: medida de segurança contra arquivos quebrados\n                img_array=cv2.imread(os.path.join(path,img))\n                training_data.append([img_array,class_num])\n                show.append(img_array)\n            except Exception as e:\n                pass\n#             plt.imshow(img_array)\n#             plt.show()\n#             break\n#         break\n\ncreate_image_set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plt.imshow(show[10930]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(training_data) #randomizar ordem das imagens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#crear duas listas. X: Imagens existentes. y: Marcas existentes\n\nX = []\ny = []\n\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n    \n#crear marcação de One-Hot-Encoding\n    \nye=pd.DataFrame(y)\n    \nNew=pd.DataFrame(columns=CATEGORIES)\nye=pd.concat([ye, New],axis=1)\n\nye.loc[ye['River'].isna()==True, ('River','Forest','AnnualCrop','HerbaceousVegetation','Highway','Industrial','Pasture','PermanentCrop','Residential','SeaLake')] = 0\nye.loc[ye[0] ==0, 'River'] = 1\nye.loc[ye[0] ==1, 'Forest'] = 1\nye.loc[ye[0] ==2, 'AnnualCrop'] = 1\nye.loc[ye[0] ==3, 'HerbaceousVegetation'] = 1\nye.loc[ye[0] ==4, 'Highway'] = 1\nye.loc[ye[0] ==5, 'Industrial'] = 1\nye.loc[ye[0] ==6, 'Pasture'] = 1\nye.loc[ye[0] ==7, 'PermanentCrop'] = 1\nye.loc[ye[0] ==8, 'Residential'] = 1\nye.loc[ye[0] ==9, 'SeaLake'] = 1\n\nye=ye.drop(ye.columns[0], axis=1)                                    \n\n#mudar pelo tipo de dado float32 que permite numeros do conjunto real\ny=ye.astype('float32')      \nprint(y)\n\n\n\n#conversão dos conjunto num numpy.array, necessario para executar a ANN    \nX = np.array(X)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.shape,X.shape)\nprint(np.isnan(y).any()) #controlar, se existem NaN (valores non-númericos) dentro do conjunto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=196) #crear um conjuntos para treinar e testar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reservar os últimos 2500 imagens por validar durante o treinamento\n\nX_val = X_train[-2500:]\ny_val = y_train[-2500:]\nX_train = X_train[:-2500]\ny_train = y_train[:-2500]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape=[64, 64, 3] #forma dum imagen utilizada: 64pixel*64pixel*3cores\n\nmodel = Sequential() #modo de escrever a ANN\n\nmodel.add(Conv2D(28, (3, 3), padding='same',input_shape=input_shape)) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(28, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2)) \n\nmodel.add(Conv2D(56, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(56, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(112, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(112, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2)) \n\nmodel.add(Flatten()) \nmodel.add(Dense(784)) \nmodel.add(Activation('relu')) \nmodel.add(Dropout(0.6)) \nmodel.add(Dense(10)) \n\nmodel.add(Activation('sigmoid')) \nadam = optimizers.Adam(lr=0.001) \nmodel.compile(optimizer=adam, loss=losses.binary_crossentropy, metrics=['accuracy'])\n\n\n          \nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Entreinamento\n\nhistory = model.fit(X_train, y_train, epochs=15,\n                    validation_data=(X_val, y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Curvas do Loss\nplt.figure(figsize=[8,6])\nplt.plot(history.history['loss'],'r',linewidth=3.0)\nplt.plot(history.history['val_loss'],'b',linewidth=3.0)\nplt.legend(['Training loss', 'Validation Loss'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Loss',fontsize=16)\nplt.title('Loss Curves',fontsize=16)\n \n# Curvas da precisão\nplt.figure(figsize=[8,6])\nplt.plot(history.history['accuracy'],'r',linewidth=3.0)\nplt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\nplt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Accuracy',fontsize=16)\nplt.title('Accuracy Curves',fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predição por X_test\n\npreds2 = model.predict(X_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a matrix de confusão, mostrando o rácio de sucesso da ANN\n\n\nprint(y_test.shape)\ny_test= np.array([np.argmax(y) for y in y_test])\ny_predict=np.array([ np.argmax(p) for p in preds2])\nprint(y_test.shape)\nprint(y_predict.shape)\nconfusion=confusion_matrix(y_test, y_predict)\nsns.heatmap(confusion, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5, \n            yticklabels='r''f''a''v''h''i''p''c''d''s',xticklabels='r''f''a''v''h''i''p''c''d''s')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}