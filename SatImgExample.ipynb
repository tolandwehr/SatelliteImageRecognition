{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pacotes para executar operações gráfricas,tabulares,matemáticas\n\nimport numpy as np \nimport pandas as pd \nimport scipy.io as sio\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imshow\nfrom pylab import rcParams\n\n!pip install missingpy\n\n#pacotes para 'imputar' dados\nimport missingpy\nfrom missingpy import MissForest\nfrom sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Impute_data=pd.read_excel(\"/kaggle/input/impute/Impute.xlsx\")#ler conjunto de dados via pandas\n\nImpute_data #mostrar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#executar funções de 'imputar'\n\nRFORImp=MissForest()\nSKLSimple=SimpleImputer(missing_values=np.nan,strategy='median')\n\nSimple_Imp = Impute_data.fillna(method='ffill')\nSKL_Imp = pd.DataFrame(SKLSimple.fit_transform(Impute_data))\nRFOR_Tab = pd.DataFrame(RFORImp.fit_transform(Impute_data))#Random Forest Imputação e conversão por pandas\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#crear gráficos\n\nplt.plot(Simple_Imp.index,Simple_Imp ['Sedimentation'], label='Simple_Imp Sedimentation', linewidth=3, color='midnightblue')\nplt.plot(Simple_Imp.index,Simple_Imp ['Sedimentation_in_Dead_Storage'], label='Simple_Imp Sediment in Dead_Volume', linewidth=3, color='orange')\nplt.plot(SKL_Imp.index,SKL_Imp [0], label='Median_Imp Sedimentation', linewidth=3, color='darkgreen')\nplt.plot(SKL_Imp.index,SKL_Imp [1], label ='Median_Imp Sediment in Dead_Volume', linewidth=3, color='red')\nplt.plot(RFOR_Tab.index,RFOR_Tab [0], label='RFOR_IMP Sedimentation', linewidth=3, color='blueviolet')\nplt.plot(RFOR_Tab.index,RFOR_Tab [1], label ='RFOR_IMP Sediment in Dead_Volume', linewidth=3, color='saddlebrown')\n\nplt.legend(loc='right',fontsize=12)\n\n\nrcParams['figure.figsize'] = 16, 6 #aumentado tamanho do imagem produzido\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFOR_Tab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Smote_data=pd.read_excel(\"/kaggle/input/barragens-short/Barragens_Short.xlsx\")#ler conjunto de dados via pandas\nSample_Len=len(Smote_data)#numero de objetos em nosso conjunto\n\nX_train=np.array(Smote_data['ano_const'])\ny_train=np.array(Smote_data['Whole_Sed_Vs_Whole_Vol_Orig'])\n\nX_train #mostrar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X_train,y_train,'x')#conjunto original\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X_train,y_train,'x') #conjunto original\n\n\nX_diff=np.array([1955]).reshape(1,-1) \nSep_Year=np.empty([Sample_Len]) #creando clases de maioridade e minoridade. Nesso caso: Ano de construção\nfor i in range(Sample_Len):#Loop pela creçao da clase de separação\n    if X_train[i]<X_diff:\n        Sep_Year[i]=0\n    else:\n        Sep_Year[i]=1\n\nprint(y_train.shape, X_train.shape)#imprindo a extensão/as matrizes originais do conjunto\n        \nTrain_Sep_Year=np.concatenate((X_train.reshape(Sample_Len,1),y_train.reshape(Sample_Len,1)),axis=1)\n\nsmote=SMOTE()#neighbours=5)\nTrain_Sep_Year,Sep_Year=smote.fit_sample(Train_Sep_Year,Sep_Year)#iniciar e executar metodólogia de SMOTE\n\nX_train_smote, y_train_smote=np.hsplit(Train_Sep_Year,2)\n\n#y_train_smote=y_train_smote.reshape(Smote_Num,)\n\nplt.plot(X_train_smote,y_train_smote,'.')\nrcParams['figure.figsize'] = 16, 6 \n\nprint(X_train_smote.shape,y_train_smote.shape)#imprindo a extensão/as matrizes originais do conjunto aumentado","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px #pacote para gerar rápidamente boas gráficos\n\ndf = px.data.gapminder() #as vezes conjuntos de testes já são implementatos nos pacotes\n\nfig = px.scatter(df.query(\"year==2007\"), x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n           hover_name=\"country\", log_x=True, size_max=60)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", animation_group=\"country\",\n           size=\"pop\", color=\"continent\", hover_name=\"country\", facet_col=\"continent\",\n           log_x=True, size_max=45, range_x=[100,100000], range_y=[25,90])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# pacotes escencias por certas funciones como randomizar ou gerar certas representações gráficas \nimport os\nimport cv2\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\n# pacotes gerais de ANN\nimport tensorflow as tf \nfrom tensorflow import keras\n\n\n#from tensorflow.keras import datasets, layers, models\n\n# pacotes por certas operções ou câmaras de ANN\nfrom tensorflow.keras import optimizers, losses, utils \nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, Dropout\nfrom tensorflow.keras.models import Model, Sequential \nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.regularizers import l2\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATADIR = '/kaggle/input/eurosat/2750/' #lugar superior do conjunto de imagens\nCATEGORIES = [\"River\",\"Forest\",\"AnnualCrop\",\"HerbaceousVegetation\",\"Highway\",\"Industrial\",\"Pasture\",\"PermanentCrop\",\"Residential\",\"SeaLake\"]#conjuntos das categórias\n\ntraining_data = [] #lista vazia\nshow = []\n\n#rotação sobre Datadir e Categorias para a)marcar cada categoria com um número único b)unificar as imanges num arquivo só  \n        \n\ndef create_image_set():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)  \n        for img in os.listdir(path):\n            try: # try-except-pass: medida de segurança contra arquivos quebrados\n                img_array=cv2.imread(os.path.join(path,img))#,cv2.IMREAD_GRAYSCALE) \n                training_data.append([img_array,class_num])\n                show.append(img_array)\n            except Exception as e:\n                pass\n#             plt.imshow(img_array)#,cmap=\"gray\")\n#             plt.show()\n#             break\n#         break\n\ncreate_image_set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plt.imshow(show[1866]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(training_data) #randomizar ordem das imagens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#crear duas listas. X: Imagens existentes. y: Marcas existentes\n\nX = []\ny = []\n\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n    \n#crear marcação de One-Hot-Encoding\n    \nye=pd.DataFrame(y)\n    \nNew=pd.DataFrame(columns=CATEGORIES)\nye=pd.concat([ye, New],axis=1)\n\nye.loc[ye['River'].isna()==True, ('River','Forest','AnnualCrop','HerbaceousVegetation','Highway','Industrial','Pasture','PermanentCrop','Residential','SeaLake')] = 0\nye.loc[ye[0] ==0, 'River'] = 1\nye.loc[ye[0] ==1, 'Forest'] = 1\nye.loc[ye[0] ==2, 'AnnualCrop'] = 1\nye.loc[ye[0] ==3, 'HerbaceousVegetation'] = 1\nye.loc[ye[0] ==4, 'Highway'] = 1\nye.loc[ye[0] ==5, 'Industrial'] = 1\nye.loc[ye[0] ==6, 'Pasture'] = 1\nye.loc[ye[0] ==7, 'PermanentCrop'] = 1\nye.loc[ye[0] ==8, 'Residential'] = 1\nye.loc[ye[0] ==9, 'SeaLake'] = 1\n\nye=ye.drop(ye.columns[0], axis=1)                                    \n\n#mudar pelo tipo de dado float32 que permite numeros do conjunto real\ny=ye.astype('float32')      \nprint(y)\n\n\n\n#conversão dos conjunto num numpy.array, necessario para executar a ANN    \nX = np.array(X)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.shape,X.shape)\nprint(np.isnan(y).any()) #controlar, se existem NaN (valores non-númericos) dentro do conjunto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=196) #crear um conjuntos para treinar e testar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reservar os últimos 2500 imagens por validar durante o treinamento\n\nX_val = X_train[-2500:]\ny_val = y_train[-2500:]\nX_train = X_train[:-2500]\ny_train = y_train[:-2500]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape=[64, 64, 3] #forma dum imagen utilizada: 64pixel*64pixel*3cores\n\nmodel = Sequential() #modo de escrever a ANN\n\nmodel.add(Conv2D(28, (3, 3), padding='same',input_shape=input_shape)) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(28, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2)) \n\nmodel.add(Conv2D(56, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(56, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(112, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(Conv2D(112, (3, 3), padding='same')) \nmodel.add(Activation('relu')) \nmodel.add(MaxPool2D(2,2)) \n\nmodel.add(Flatten()) \nmodel.add(Dense(784)) \nmodel.add(Activation('relu')) \nmodel.add(Dropout(0.6)) \nmodel.add(Dense(10)) \n\nmodel.add(Activation('sigmoid')) \nadam = optimizers.Adam(lr=0.001) \nmodel.compile(optimizer=adam, loss=losses.binary_crossentropy, metrics=['accuracy'])\n\n\n          \nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Entreinamento\n\nhistory = model.fit(X_train, y_train, epochs=25,\n                    validation_data=(X_val, y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Curvas do Loss\nplt.figure(figsize=[8,6])\nplt.plot(history.history['loss'],'r',linewidth=3.0)\nplt.plot(history.history['val_loss'],'b',linewidth=3.0)\nplt.legend(['Training loss', 'Validation Loss'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Loss',fontsize=16)\nplt.title('Loss Curves',fontsize=16)\n \n# Curvas da precisão\nplt.figure(figsize=[8,6])\nplt.plot(history.history['accuracy'],'r',linewidth=3.0)\nplt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\nplt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Accuracy',fontsize=16)\nplt.title('Accuracy Curves',fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predição por X_test\n\npreds2 = model.predict(X_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"r=River\\nf=Forest\\na=AnnualCrop\\nv=HerbaceousVegetation\\nh=Highway\\ni=Industrial\\np=Pasture\\nc=PermanentCrop\\nd=Residential\\ns=SeaLake\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a matrix de confusão, mostrando o rácio de sucesso da ANN\n\n\nprint(y_test.shape)\ny_test= np.array([np.argmax(y) for y in y_test])\ny_predict=np.array([ np.argmax(p) for p in preds2])\nprint(y_test.shape)\nprint(y_predict.shape)\nconfusion=confusion_matrix(y_test, y_predict)\nsns.heatmap(confusion, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5, \n            yticklabels='r''f''a''v''h''i''p''c''d''s',xticklabels='r''f''a''v''h''i''p''c''d''s')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\n\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU,UpSampling2D, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n#from tensorflow.keras.layers.advanced_activations import LeakyReLU\n#from tensorflow.keras.layers.convolutional import \nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport sys\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DCGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.latent_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise as input and generates imgs\n        z = Input(shape=(self.latent_dim,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        model = Sequential()\n\n        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n        model.add(Reshape((7, 7, 128)))\n        model.add(UpSampling2D())\n        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        model.add(UpSampling2D())\n        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n        model.add(Activation(\"tanh\"))\n\n        model.summary()\n\n        noise = Input(shape=(self.latent_dim,))\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Flatten())\n        model.add(Dense(1, activation='sigmoid'))\n\n        model.summary()\n\n        img = Input(shape=self.img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = X_train / 127.5 - 1.\n        X_train = np.expand_dims(X_train, axis=3)\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half of images\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n\n            # Sample noise and generate a batch of new images\n            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator (real classified as ones and generated as zeros)\n            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Train the generator (wants discriminator to mistake images as real)\n            g_loss = self.combined.train_on_batch(noise, valid)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        plt.show()\n        #fig.savefig(\"../working/mnist_%d.png\" % epoch)\n        plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    dcgan = DCGAN()\n    dcgan.train(epochs=51, batch_size=32, save_interval=25)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}